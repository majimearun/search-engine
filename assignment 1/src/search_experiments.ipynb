{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import spacy\n",
    "from LinkedList import LinkedList\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv('/home/majime/programming/github/information-retrieval-assignments/assignment 1/tokenized/auto.csv')\n",
    "property_df = pd.read_csv('/home/majime/programming/github/information-retrieval-assignments/assignment 1/tokenized/property.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_postings_list(x):\n",
    "    x = str(x)\n",
    "    posting_list = set()\n",
    "    for word in x.split():\n",
    "        posting_list.add(word.lower())\n",
    "    posting_list = list(posting_list)\n",
    "    # remove strings with only punctuations\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~=+'''\n",
    "    for word in posting_list:\n",
    "        if word in punctuations:\n",
    "            posting_list.remove(word)\n",
    "    return sorted((posting_list))\n",
    "\n",
    "auto_df['posting_list'] = auto_df['tokenized'].apply(create_postings_list)\n",
    "property_df['posting_list'] = property_df['tokenized'].apply(create_postings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([auto_df, property_df])\n",
    "main_df = main_df.reset_index(drop=True)\n",
    "corpus = set()\n",
    "for l in main_df.posting_list:\n",
    "    for word in l:\n",
    "        corpus.add(word)\n",
    "corpus = sorted(list(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_list(df):\n",
    "    inverted_list = {}\n",
    "    for word in corpus:\n",
    "        inverted_list[word] = LinkedList()\n",
    "    for row in df.iterrows():\n",
    "        l = row[1][\"posting_list\"]\n",
    "        for word in l:\n",
    "            inverted_list[word].append(row[0])\n",
    "    for word in inverted_list:\n",
    "        inverted_list[word].sort()\n",
    "    return inverted_list\n",
    "\n",
    "inverted_list = create_inverted_list(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_rotations(s):\n",
    "    rotations = []\n",
    "    for i in range(len(s)):\n",
    "        rotations.append(s[i:] + s[:i])\n",
    "    return rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def permuterm_indexing(inv_list):\n",
    "    perm_index = {}\n",
    "    for word in inv_list:\n",
    "        word_perm = word + \"$\"\n",
    "        rotations = get_all_rotations(word_perm)\n",
    "        for rotation in rotations:\n",
    "            q = rotation.split(\"$\")[-1]\n",
    "            if q not in perm_index:\n",
    "                perm_index[q] = LinkedList()\n",
    "            perm_index[q].append(word)\n",
    "    return perm_index\n",
    "\n",
    "    \n",
    "perm_index = permuterm_indexing(inverted_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_permuterm_indexing(inv_list):\n",
    "    rev_perm_index = {}\n",
    "    for word in inv_list:\n",
    "        word_perm = \"$\" + word\n",
    "        word_perm = word_perm[::-1] \n",
    "        rotations = get_all_rotations(word_perm)\n",
    "        for rotation in rotations:\n",
    "            q = rotation.split(\"$\")[-1]\n",
    "            if q not in rev_perm_index:\n",
    "                rev_perm_index[q] = LinkedList()\n",
    "            rev_perm_index[q].append(word)\n",
    "    return rev_perm_index\n",
    "\n",
    "rev_perm_index = reverse_permuterm_indexing(inverted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_permuterm_indexing(query, perm_index):\n",
    "    result = []\n",
    "    query = query + \"$\"\n",
    "    rotations = get_all_rotations(query)\n",
    "    for rotation in rotations:\n",
    "        if rotation[0] == \"*\":\n",
    "            q = rotation[2:]\n",
    "            if q in perm_index:\n",
    "                for word in perm_index[q]:\n",
    "                    result.append(word.data)\n",
    "    return result\n",
    "    \n",
    "def right_permuterm_indexing(query, rev_perm_index):\n",
    "    result = []\n",
    "    query = \"$\" + query\n",
    "    query = query[::-1]\n",
    "    rotations = get_all_rotations(query)\n",
    "    for rotation in rotations:\n",
    "        if rotation[0] == \"*\":\n",
    "            q = rotation[2:]\n",
    "            if q in rev_perm_index:\n",
    "                for word in rev_perm_index[q]:\n",
    "                    result.append(word.data)\n",
    "    return result\n",
    "\n",
    "def query_permuterm_index(query, perm_index, rev_perm_index, inv_list):\n",
    "    result = []\n",
    "    if \"*\" in query:\n",
    "        if query[-1] == \"*\":\n",
    "            result = left_permuterm_indexing(query, perm_index)\n",
    "        elif query[0] == \"*\":\n",
    "            result = right_permuterm_indexing(query, rev_perm_index)\n",
    "                            \n",
    "        else:\n",
    "            halves = query.split(\"*\")\n",
    "            left_result = left_permuterm_indexing(halves[0] + \"*\", perm_index)\n",
    "            right_result = right_permuterm_indexing(\"*\" + halves[-1], rev_perm_index)\n",
    "            result = list(set(left_result) & set(right_result))\n",
    "            \n",
    "    docs = []\n",
    "    for word in result:\n",
    "        for id in inv_list[word]:\n",
    "            docs.append(id.data)    \n",
    "    return sorted(list(set(docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = query_permuterm_index(\"g*l*e\", perm_index, rev_perm_index, inverted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 10,\n",
       " 12,\n",
       " 24,\n",
       " 29,\n",
       " 30,\n",
       " 75,\n",
       " 96,\n",
       " 128,\n",
       " 157,\n",
       " 236,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 276,\n",
       " 341,\n",
       " 471,\n",
       " 498,\n",
       " 520,\n",
       " 590,\n",
       " 630,\n",
       " 712,\n",
       " 744,\n",
       " 853,\n",
       " 881,\n",
       " 889,\n",
       " 897,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 914,\n",
       " 915,\n",
       " 919,\n",
       " 923,\n",
       " 924,\n",
       " 932,\n",
       " 940,\n",
       " 941,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 958,\n",
       " 1028,\n",
       " 1093,\n",
       " 1108,\n",
       " 1110,\n",
       " 1111,\n",
       " 1129,\n",
       " 1132,\n",
       " 1208,\n",
       " 1210,\n",
       " 1293,\n",
       " 1297,\n",
       " 1298,\n",
       " 1299,\n",
       " 1308,\n",
       " 1315,\n",
       " 1325,\n",
       " 1327,\n",
       " 1332,\n",
       " 1337,\n",
       " 1344,\n",
       " 1351,\n",
       " 1357,\n",
       " 1363,\n",
       " 1364,\n",
       " 1365,\n",
       " 1367,\n",
       " 1370,\n",
       " 1371,\n",
       " 1372,\n",
       " 1377,\n",
       " 1388,\n",
       " 1389,\n",
       " 1390,\n",
       " 1391,\n",
       " 1394,\n",
       " 1401,\n",
       " 1420,\n",
       " 1443,\n",
       " 1461,\n",
       " 1463,\n",
       " 1464,\n",
       " 1466,\n",
       " 1510,\n",
       " 1516,\n",
       " 1519,\n",
       " 1566,\n",
       " 1571,\n",
       " 1647,\n",
       " 1669,\n",
       " 1702,\n",
       " 1731,\n",
       " 1748,\n",
       " 1781,\n",
       " 1794,\n",
       " 1820,\n",
       " 1845,\n",
       " 1847,\n",
       " 1848,\n",
       " 1850,\n",
       " 1854,\n",
       " 1856,\n",
       " 1858,\n",
       " 1859,\n",
       " 1884,\n",
       " 1887,\n",
       " 1908,\n",
       " 1920,\n",
       " 1923,\n",
       " 1931,\n",
       " 1936,\n",
       " 1954,\n",
       " 1973,\n",
       " 1989,\n",
       " 2009,\n",
       " 2256,\n",
       " 2265,\n",
       " 2277,\n",
       " 2280,\n",
       " 2285,\n",
       " 2294,\n",
       " 2295,\n",
       " 2298,\n",
       " 2301,\n",
       " 2310,\n",
       " 2358,\n",
       " 2360,\n",
       " 2366,\n",
       " 2380,\n",
       " 2387,\n",
       " 2394,\n",
       " 2403,\n",
       " 2413,\n",
       " 2414,\n",
       " 2457,\n",
       " 2458,\n",
       " 2460,\n",
       " 2474,\n",
       " 2476,\n",
       " 2479,\n",
       " 2480,\n",
       " 2483,\n",
       " 2487,\n",
       " 2500,\n",
       " 2502,\n",
       " 2503,\n",
       " 2504,\n",
       " 2505,\n",
       " 2517,\n",
       " 2533,\n",
       " 2537,\n",
       " 2549,\n",
       " 2572,\n",
       " 2582,\n",
       " 2584,\n",
       " 2586,\n",
       " 2587,\n",
       " 2590,\n",
       " 2597,\n",
       " 2605,\n",
       " 2613,\n",
       " 2626,\n",
       " 2627,\n",
       " 2634,\n",
       " 2635,\n",
       " 2644,\n",
       " 2648,\n",
       " 2651,\n",
       " 2653,\n",
       " 2654,\n",
       " 2655,\n",
       " 2663,\n",
       " 2675,\n",
       " 2677,\n",
       " 2679,\n",
       " 2699,\n",
       " 2718,\n",
       " 2733,\n",
       " 2748,\n",
       " 2780,\n",
       " 2791,\n",
       " 2842,\n",
       " 2846,\n",
       " 2924,\n",
       " 2951,\n",
       " 2985,\n",
       " 3009,\n",
       " 3034,\n",
       " 3047,\n",
       " 3055,\n",
       " 3057,\n",
       " 3098,\n",
       " 3102,\n",
       " 3103,\n",
       " 3110,\n",
       " 3115,\n",
       " 3117,\n",
       " 3121,\n",
       " 3122,\n",
       " 3127,\n",
       " 3144,\n",
       " 3178,\n",
       " 3203,\n",
       " 3205,\n",
       " 3217,\n",
       " 3218]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query(queries, _and=False):\n",
    "    docs = []\n",
    "    for query in queries:\n",
    "        if \"*\" in query:\n",
    "            docs.append(query_permuterm_index(query, perm_index, rev_perm_index, inverted_list))\n",
    "            \n",
    "        else:\n",
    "            intermediate_docs = []\n",
    "            for id in inverted_list[query]:\n",
    "                intermediate_docs.append(id.data)\n",
    "            docs.append(intermediate_docs)\n",
    "    # return docs\n",
    "    if not _and:   \n",
    "        # return union of all sublists in docs\n",
    "        result = []\n",
    "        for l in docs:\n",
    "            for id in l:\n",
    "                if id not in result:\n",
    "                    result.append(id)\n",
    "        return sorted(result)\n",
    "    else:\n",
    "        result = set(docs[0])\n",
    "        for l in docs:\n",
    "            result = result.intersection(set(l))\n",
    "        return sorted(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = multi_query([\"g*e\", \"car\"], _and=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 914,\n",
       " 932,\n",
       " 940,\n",
       " 941,\n",
       " 1364,\n",
       " 1370,\n",
       " 1391,\n",
       " 1443,\n",
       " 1516,\n",
       " 1989,\n",
       " 2387,\n",
       " 2476,\n",
       " 2487,\n",
       " 2582,\n",
       " 2586,\n",
       " 2634,\n",
       " 2655,\n",
       " 2718,\n",
       " 2791]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_step_one(queries):\n",
    "    # seperate queries into two lists, and and or lists. and words have double quotes around them\n",
    "    and_queries = []\n",
    "    or_queries = []\n",
    "    for query in queries:\n",
    "        if query[0] == '\"' and query[-1] == '\"':\n",
    "            and_queries.append(query[1:-1])\n",
    "        else:\n",
    "            or_queries.append(query)\n",
    "    if len(and_queries) == 0:\n",
    "        return multi_query(or_queries)\n",
    "    if len(or_queries) == 0:\n",
    "        return multi_query(and_queries, _and=True)\n",
    "    and_results = multi_query(and_queries, _and=True)\n",
    "    or_results = multi_query(or_queries)\n",
    "    return sorted(list(set(and_results) & set(or_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 33,\n",
       " 67,\n",
       " 92,\n",
       " 96,\n",
       " 101,\n",
       " 121,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 145,\n",
       " 287,\n",
       " 288,\n",
       " 364,\n",
       " 469,\n",
       " 568,\n",
       " 629,\n",
       " 634,\n",
       " 635,\n",
       " 687,\n",
       " 707,\n",
       " 709,\n",
       " 726,\n",
       " 733,\n",
       " 734,\n",
       " 890,\n",
       " 911,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 925,\n",
       " 928,\n",
       " 936,\n",
       " 937,\n",
       " 1032,\n",
       " 1033,\n",
       " 1047,\n",
       " 1094,\n",
       " 1097,\n",
       " 1112,\n",
       " 1130,\n",
       " 1144,\n",
       " 1146,\n",
       " 1163,\n",
       " 1164,\n",
       " 1171,\n",
       " 1292,\n",
       " 1338,\n",
       " 1339,\n",
       " 1350,\n",
       " 1351,\n",
       " 1719,\n",
       " 2271,\n",
       " 2474,\n",
       " 2492,\n",
       " 2495,\n",
       " 2599,\n",
       " 2636]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_step_one([\"\\\"acci*t\\\"\", \"bodily\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3241"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_name                                        7thEditionPolicy\n",
       "page_number                                                         1\n",
       "paragraph_number                                                    0\n",
       "text                 \\nContents     \\nIntroduction \\n1   \\nDefinit...\n",
       "tokenized           contents introduction definition agreement com...\n",
       "posting_list        [accident, agreement, auto, bodily, cancellati...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_word_index(df):\n",
    "    n_word_index = {}\n",
    "    for row in df.iterrows():\n",
    "        text = str(row[1][\"tokenized\"])\n",
    "        text = text.split()\n",
    "        for i in range(len(text) - 1):\n",
    "            n_word = text[i] + \" \" + text[i+1]\n",
    "            if n_word not in n_word_index:\n",
    "                n_word_index[n_word] = LinkedList()\n",
    "            n_word_index[n_word].append(row[0])\n",
    "    return n_word_index\n",
    "\n",
    "n_word_index = make_n_word_index(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in n_word_index:\n",
    "    n_word_index[key].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_n_word_index(query, n_word_index):\n",
    "    result = []\n",
    "    for id in n_word_index[query]:\n",
    "        result.append(id.data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_query(query, n_word_index):\n",
    "    words = query.split()\n",
    "    biwords = []\n",
    "    for i in range(len(words) - 1):\n",
    "        biwords.append(words[i] + \" \" + words[i+1])\n",
    "    result = []\n",
    "    for bw in biwords:\n",
    "        result.append(query_n_word_index(bw, n_word_index))\n",
    "    final = set(result[0])\n",
    "    for l in result:\n",
    "        final = final.intersection(set(l))\n",
    "    return sorted(list(final))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_query(\"liability policy sue\", n_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_term_frequency_scores(df, query, inverted_list, perm_index, rev_perm_index):\n",
    "    scores = []\n",
    "    for row in df.iterrows():\n",
    "        text = str(row[1][\"tokenized\"])\n",
    "        text = text.split()\n",
    "        score = 0\n",
    "        for q in query:\n",
    "            if q in text:\n",
    "                if \"*\" not in q:\n",
    "                    doc_freq = len(inverted_list[q]) + 1\n",
    "\n",
    "                    score += (1 + np.log10(text.count(q)))*(np.log10(len(df)/doc_freq))\n",
    "                else:\n",
    "                    if q[-1] == \"*\":\n",
    "                        left_result = left_permuterm_indexing(q, perm_index)\n",
    "                        for word in left_result:\n",
    "                            doc_freq = len(inverted_list[word]) + 1\n",
    "                            score += (1 + np.log10(text.count(word)))*(np.log10(len(df)/doc_freq))\n",
    "                    elif q[0] == \"*\":\n",
    "                        right_result = right_permuterm_indexing(q, rev_perm_index)\n",
    "                        for word in right_result:\n",
    "                            doc_freq = len(inverted_list[word]) + 1\n",
    "                            score += (1 + np.log10(text.count(word)))*(np.log10(len(df)/doc_freq))\n",
    "                    else:\n",
    "                        halves = q.split(\"*\")\n",
    "                        left_result = left_permuterm_indexing(halves[0] + \"*\", perm_index)\n",
    "                        right_result = right_permuterm_indexing(\"*\" + halves[-1], rev_perm_index)\n",
    "                        result = list(set(left_result) & set(right_result))\n",
    "                        for word in result:\n",
    "                            doc_freq = len(inverted_list[word]) + 1\n",
    "                            score += (1 + np.log10(text.count(word)))*(np.log10(len(df)/doc_freq))\n",
    "                \n",
    "        scores.append((row[0], score))\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = engine_step_one([\"\\\"acci*t\\\"\", \"bodily\", \"harm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df = main_df.iloc[docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_inverted_list = create_inverted_list(mid_df)\n",
    "mid_perm_index = permuterm_indexing(mid_inverted_list)\n",
    "mid_rev_perm_index = reverse_permuterm_indexing(mid_perm_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>paragraph_number</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>posting_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7thEditionPolicy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nContents     \\nIntroduction \\n1   \\nDefinit...</td>\n",
       "      <td>contents introduction definition agreement com...</td>\n",
       "      <td>[accident, agreement, auto, bodily, cancellati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7thEditionPolicy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n2 \\nDefinitions  Throughout this policy: \\n...</td>\n",
       "      <td>definition policy refer company issue policy r...</td>\n",
       "      <td>[accident, additional, arise, ask, atv, auto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7thEditionPolicy</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3  unless such use is incidental to your bus...</td>\n",
       "      <td>use incidental business instal maintain repair...</td>\n",
       "      <td>[accident, accidental, adoption, agent, agree,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7thEditionPolicy</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n4 \\nCompulsory \\nInsurance \\nThere are four...</td>\n",
       "      <td>compulsory insurance part compulsory insurance...</td>\n",
       "      <td>[access, accident, amount, apply, authorize, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7thEditionPolicy</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nCompulsory  Insurance  (Continued) \\n7\\nW...</td>\n",
       "      <td>compulsory insurance continued pay pip benefit...</td>\n",
       "      <td>[accident, agree, alcohol, arrest, auto, avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>eSols Property Owners Commercial Policy Wordin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pen Underwriting Limited is authorised and reg...</td>\n",
       "      <td>pen underwriting limited authorise regulate fi...</td>\n",
       "      <td>[accident, accordingly, adjuster, admit, advic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>eSols Property Owners Commercial Policy Wordin...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Pen Underwriting Limited is authorised and reg...</td>\n",
       "      <td>pen underwriting limited authorise regulate fi...</td>\n",
       "      <td>[accident, accidental, act, action, agree, aid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>eSols Property Owners Commercial Policy Wordin...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Pen Underwriting Limited is authorised and reg...</td>\n",
       "      <td>pen underwriting limited authorise regulate fi...</td>\n",
       "      <td>[accident, accusation, aid, alleged, alter, am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>Residential-Property-Owners-Policy-Wording-1910</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39\\nArch Residential Property Owners 1910 g. \\...</td>\n",
       "      <td>arch residential property owners tool die cut ...</td>\n",
       "      <td>[accident, accuracy, action, agency, ammonia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>BRIT-PO-Policy-Wording-May-2016-1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nPage | 8   G \\nGlass \\nmeans:  1. \\nFixed g...</td>\n",
       "      <td>page g glass mean fix glass mirror insured pre...</td>\n",
       "      <td>[access, accident, affect, agency, alarm, alle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          document_name  page_number  \\\n",
       "1                                      7thEditionPolicy            1   \n",
       "3                                      7thEditionPolicy            3   \n",
       "4                                      7thEditionPolicy            4   \n",
       "5                                      7thEditionPolicy            5   \n",
       "8                                      7thEditionPolicy            8   \n",
       "...                                                 ...          ...   \n",
       "2474  eSols Property Owners Commercial Policy Wordin...            1   \n",
       "2492  eSols Property Owners Commercial Policy Wordin...           19   \n",
       "2495  eSols Property Owners Commercial Policy Wordin...           22   \n",
       "2599    Residential-Property-Owners-Policy-Wording-1910           39   \n",
       "2636                  BRIT-PO-Policy-Wording-May-2016-1            7   \n",
       "\n",
       "      paragraph_number                                               text  \\\n",
       "1                    0   \\nContents     \\nIntroduction \\n1   \\nDefinit...   \n",
       "3                    0   \\n2 \\nDefinitions  Throughout this policy: \\n...   \n",
       "4                    0    3  unless such use is incidental to your bus...   \n",
       "5                    0   \\n4 \\nCompulsory \\nInsurance \\nThere are four...   \n",
       "8                    0     \\nCompulsory  Insurance  (Continued) \\n7\\nW...   \n",
       "...                ...                                                ...   \n",
       "2474                 0  Pen Underwriting Limited is authorised and reg...   \n",
       "2492                 0  Pen Underwriting Limited is authorised and reg...   \n",
       "2495                 0  Pen Underwriting Limited is authorised and reg...   \n",
       "2599                 0  39\\nArch Residential Property Owners 1910 g. \\...   \n",
       "2636                 0   \\nPage | 8   G \\nGlass \\nmeans:  1. \\nFixed g...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "1     contents introduction definition agreement com...   \n",
       "3     definition policy refer company issue policy r...   \n",
       "4     use incidental business instal maintain repair...   \n",
       "5     compulsory insurance part compulsory insurance...   \n",
       "8     compulsory insurance continued pay pip benefit...   \n",
       "...                                                 ...   \n",
       "2474  pen underwriting limited authorise regulate fi...   \n",
       "2492  pen underwriting limited authorise regulate fi...   \n",
       "2495  pen underwriting limited authorise regulate fi...   \n",
       "2599  arch residential property owners tool die cut ...   \n",
       "2636  page g glass mean fix glass mirror insured pre...   \n",
       "\n",
       "                                           posting_list  \n",
       "1     [accident, agreement, auto, bodily, cancellati...  \n",
       "3     [accident, additional, arise, ask, atv, auto, ...  \n",
       "4     [accident, accidental, adoption, agent, agree,...  \n",
       "5     [access, accident, amount, apply, authorize, a...  \n",
       "8     [accident, agree, alcohol, arrest, auto, avoid...  \n",
       "...                                                 ...  \n",
       "2474  [accident, accordingly, adjuster, admit, advic...  \n",
       "2492  [accident, accidental, act, action, agree, aid...  \n",
       "2495  [accident, accusation, aid, alleged, alter, am...  \n",
       "2599  [accident, accuracy, action, agency, ammonia, ...  \n",
       "2636  [access, accident, affect, agency, alarm, alle...  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 3.4269605488201202),\n",
       " (15, 3.155552199515261),\n",
       " (890, 3.155552199515261),\n",
       " (1, 2.975558083125821),\n",
       " (5, 2.975558083125821),\n",
       " (92, 2.975558083125821),\n",
       " (922, 2.975558083125821),\n",
       " (923, 2.975558083125821),\n",
       " (925, 2.975558083125821),\n",
       " (1339, 2.975558083125821),\n",
       " (1351, 2.975558083125821),\n",
       " (2495, 2.975558083125821),\n",
       " (14, 2.743505307560158),\n",
       " (22, 2.743505307560158),\n",
       " (27, 2.743505307560158),\n",
       " (128, 2.743505307560158),\n",
       " (921, 2.743505307560158),\n",
       " (1032, 2.743505307560158),\n",
       " (1338, 2.743505307560158),\n",
       " (1350, 2.743505307560158),\n",
       " (8, 2.4164452897785447),\n",
       " (11, 2.4164452897785447),\n",
       " (16, 2.4164452897785447),\n",
       " (25, 2.4164452897785447),\n",
       " (29, 2.4164452897785447),\n",
       " (33, 2.4164452897785447),\n",
       " (145, 2.4164452897785447),\n",
       " (687, 2.4164452897785447),\n",
       " (911, 2.4164452897785447),\n",
       " (928, 2.4164452897785447),\n",
       " (1130, 2.4164452897785447),\n",
       " (1163, 2.4164452897785447),\n",
       " (1719, 2.4164452897785447),\n",
       " (2271, 2.4164452897785447),\n",
       " (2474, 2.4164452897785447),\n",
       " (2492, 2.4164452897785447),\n",
       " (3, 1.8573324964312685),\n",
       " (4, 1.8573324964312685),\n",
       " (10, 1.8573324964312685),\n",
       " (67, 1.8573324964312685),\n",
       " (96, 1.8573324964312685),\n",
       " (101, 1.8573324964312685),\n",
       " (121, 1.8573324964312685),\n",
       " (127, 1.8573324964312685),\n",
       " (130, 1.8573324964312685),\n",
       " (287, 1.8573324964312685),\n",
       " (288, 1.8573324964312685),\n",
       " (364, 1.8573324964312685),\n",
       " (469, 1.8573324964312685),\n",
       " (568, 1.8573324964312685),\n",
       " (629, 1.8573324964312685),\n",
       " (634, 1.8573324964312685),\n",
       " (635, 1.8573324964312685),\n",
       " (707, 1.8573324964312685),\n",
       " (709, 1.8573324964312685),\n",
       " (726, 1.8573324964312685),\n",
       " (733, 1.8573324964312685),\n",
       " (734, 1.8573324964312685),\n",
       " (936, 1.8573324964312685),\n",
       " (937, 1.8573324964312685),\n",
       " (1033, 1.8573324964312685),\n",
       " (1047, 1.8573324964312685),\n",
       " (1094, 1.8573324964312685),\n",
       " (1097, 1.8573324964312685),\n",
       " (1112, 1.8573324964312685),\n",
       " (1144, 1.8573324964312685),\n",
       " (1146, 1.8573324964312685),\n",
       " (1164, 1.8573324964312685),\n",
       " (1171, 1.8573324964312685),\n",
       " (1292, 1.8573324964312685),\n",
       " (2599, 1.8573324964312685),\n",
       " (2636, 1.8573324964312685)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_term_frequency_scores(mid_df, [\"\\\"acci*t\\\"\", \"bodily\"], mid_inverted_list, mid_perm_index, mid_rev_perm_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Effective (2016-06-01) \n",
      "FSCO (1215E.2) \n",
      "© Queen's Printer for Ontario, 2016 \n",
      "(OAP 1) Owner’s Policy \n",
      "Page 43   \n",
      "Example  We will not pay for a tire blow-out in normal driving, but if the tire is destroyed \n",
      "in a collision and you have Collision or Upset Coverage, we will cover that loss \n",
      "up to the value of your tire at the time of the incident.  We won't pay for loss or damage:   resulting from a dishonest claim of ownership, illegal disposal, or theft of the \n",
      "automobile by anyone who has legal possession of it under a written agreement (a \n",
      "mortgage, conditional sale, lease or other similar agreement);   resulting from a change in ownership that is agreed to, even if that change was brought \n",
      "about by trickery or fraud;  Example  Late one evening at a party, you sell your car to a stranger in return for a \n",
      "cheque. A week later the cheque bounces. We will not cover the loss.   caused by radioactive contamination;   to contents of automobiles and trailers, other than their equipment; and   in excess of $25 for recorded material and equipment for use with a playing or \n",
      "recording unit. We will not pay for recorded material and equipment not contained \n",
      "within or attached to the playing or recording unit. Recorded material includes, but is \n",
      "not limited to, tapes, compact discs, video cassettes and digital video discs.  7.2.2 Illegal Use  We won't pay for loss or damage caused in an incident:   if you are unable to maintain proper control of the automobile because you are driving \n",
      "or operating the automobile while under the influence of intoxicating substances;   if you are convicted of one of the following offences under the Criminal Code of \n",
      "Canada relating to the operation, care or control of the automobile, or committed by \n",
      "means of an automobile, or any similar offence under any law in Canada or the United \n",
      "States: \n",
      "o causing bodily harm by criminal negligence \n",
      "o dangerous operation of motor vehicles \n",
      "o failure to stop at the scene of an accident \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(main_df.iloc[936].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df.iloc[22].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "658a82028ab00f880bc6bcdff014f37899cf9fd6fbfdda117e2e46094372bdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
