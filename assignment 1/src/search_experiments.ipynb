{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import spacy\n",
    "from LinkedList import LinkedList\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv('/home/majime/programming/github/information-retrieval-assignments/assignment 1/tokenized/auto.csv')\n",
    "property_df = pd.read_csv('/home/majime/programming/github/information-retrieval-assignments/assignment 1/tokenized/property.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_postings_list(x):\n",
    "    x = str(x)\n",
    "    posting_list = set()\n",
    "    for word in x.split():\n",
    "        posting_list.add(word.lower())\n",
    "    posting_list = list(posting_list)\n",
    "    # remove strings with only punctuations\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~=+'''\n",
    "    for word in posting_list:\n",
    "        if word in punctuations:\n",
    "            posting_list.remove(word)\n",
    "    return sorted((posting_list))\n",
    "\n",
    "auto_df['posting_list'] = auto_df['tokenized'].apply(create_postings_list)\n",
    "property_df['posting_list'] = property_df['tokenized'].apply(create_postings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([auto_df, property_df])\n",
    "main_df = main_df.reset_index(drop=True)\n",
    "corpus = set()\n",
    "for l in main_df.posting_list:\n",
    "    for word in l:\n",
    "        corpus.add(word)\n",
    "corpus = sorted(list(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_list(df):\n",
    "    inverted_list = {}\n",
    "    for word in corpus:\n",
    "        inverted_list[word] = LinkedList()\n",
    "    for row in df.iterrows():\n",
    "        l = row[1][\"posting_list\"]\n",
    "        for word in l:\n",
    "            inverted_list[word].append(row[0])\n",
    "    for word in inverted_list:\n",
    "        inverted_list[word].sort()\n",
    "    return inverted_list\n",
    "\n",
    "inverted_list = create_inverted_list(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_rotations(s):\n",
    "    rotations = []\n",
    "    for i in range(len(s)):\n",
    "        rotations.append(s[i:] + s[:i])\n",
    "    return rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def permuterm_indexing(inv_list):\n",
    "    perm_index = {}\n",
    "    for word in inv_list:\n",
    "        word_perm = word + \"$\"\n",
    "        rotations = get_all_rotations(word_perm)\n",
    "        for rotation in rotations:\n",
    "            q = rotation.split(\"$\")[-1]\n",
    "            if q not in perm_index:\n",
    "                perm_index[q] = LinkedList()\n",
    "            perm_index[q].append(word)\n",
    "    return perm_index\n",
    "\n",
    "    \n",
    "perm_index = permuterm_indexing(inverted_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_permuterm_indexing(inv_list):\n",
    "    rev_perm_index = {}\n",
    "    for word in inv_list:\n",
    "        word_perm = \"$\" + word\n",
    "        word_perm = word_perm[::-1] \n",
    "        rotations = get_all_rotations(word_perm)\n",
    "        for rotation in rotations:\n",
    "            q = rotation.split(\"$\")[-1]\n",
    "            if q not in rev_perm_index:\n",
    "                rev_perm_index[q] = LinkedList()\n",
    "            rev_perm_index[q].append(word)\n",
    "    return rev_perm_index\n",
    "\n",
    "rev_perm_index = reverse_permuterm_indexing(inverted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_permuterm_indexing(query, perm_index):\n",
    "    result = []\n",
    "    query = query + \"$\"\n",
    "    rotations = get_all_rotations(query)\n",
    "    for rotation in rotations:\n",
    "        if rotation[0] == \"*\":\n",
    "            q = rotation[2:]\n",
    "            if q in perm_index:\n",
    "                for word in perm_index[q]:\n",
    "                    result.append(word.data)\n",
    "    return result\n",
    "    \n",
    "def right_permuterm_indexing(query, rev_perm_index):\n",
    "    result = []\n",
    "    query = \"$\" + query\n",
    "    query = query[::-1]\n",
    "    rotations = get_all_rotations(query)\n",
    "    for rotation in rotations:\n",
    "        if rotation[0] == \"*\":\n",
    "            q = rotation[2:]\n",
    "            if q in rev_perm_index:\n",
    "                for word in rev_perm_index[q]:\n",
    "                    result.append(word.data)\n",
    "    return result\n",
    "\n",
    "def query_permuterm_index(query, perm_index, rev_perm_index, inv_list):\n",
    "    result = []\n",
    "    if \"*\" in query:\n",
    "        if query[-1] == \"*\":\n",
    "            result = left_permuterm_indexing(query, perm_index)\n",
    "        elif query[0] == \"*\":\n",
    "            result = right_permuterm_indexing(query, rev_perm_index)\n",
    "                            \n",
    "        else:\n",
    "            halves = query.split(\"*\")\n",
    "            left_result = left_permuterm_indexing(halves[0] + \"*\", perm_index)\n",
    "            right_result = right_permuterm_indexing(\"*\" + halves[-1], rev_perm_index)\n",
    "            result = list(set(left_result) & set(right_result))\n",
    "            \n",
    "    docs = []\n",
    "    for word in result:\n",
    "        for id in inv_list[word]:\n",
    "            docs.append(id.data)    \n",
    "    return sorted(list(set(docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = query_permuterm_index(\"g*l*e\", perm_index, rev_perm_index, inverted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37,\n",
       " 45,\n",
       " 50,\n",
       " 87,\n",
       " 102,\n",
       " 105,\n",
       " 126,\n",
       " 128,\n",
       " 129,\n",
       " 131,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 141,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 156,\n",
       " 157,\n",
       " 159,\n",
       " 161,\n",
       " 165,\n",
       " 166,\n",
       " 175,\n",
       " 212,\n",
       " 236,\n",
       " 243,\n",
       " 245,\n",
       " 251,\n",
       " 258,\n",
       " 271,\n",
       " 394,\n",
       " 399,\n",
       " 453,\n",
       " 454,\n",
       " 495,\n",
       " 498,\n",
       " 509,\n",
       " 620,\n",
       " 724,\n",
       " 741,\n",
       " 815,\n",
       " 817,\n",
       " 825,\n",
       " 848,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 870,\n",
       " 874,\n",
       " 878,\n",
       " 881,\n",
       " 896,\n",
       " 899,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 908,\n",
       " 978,\n",
       " 979,\n",
       " 981,\n",
       " 1023,\n",
       " 1036,\n",
       " 1050,\n",
       " 1160,\n",
       " 1245,\n",
       " 1246,\n",
       " 1353,\n",
       " 1395,\n",
       " 1447,\n",
       " 1523,\n",
       " 1620,\n",
       " 1734,\n",
       " 1812,\n",
       " 1861,\n",
       " 1903,\n",
       " 1908,\n",
       " 1931,\n",
       " 1979,\n",
       " 1984,\n",
       " 2038,\n",
       " 2065,\n",
       " 2083,\n",
       " 2102,\n",
       " 2205,\n",
       " 2206,\n",
       " 2454,\n",
       " 2468,\n",
       " 2475,\n",
       " 2507,\n",
       " 2531,\n",
       " 2609,\n",
       " 2622,\n",
       " 2761,\n",
       " 2763,\n",
       " 2835,\n",
       " 2839,\n",
       " 2842,\n",
       " 2843,\n",
       " 2849,\n",
       " 2850,\n",
       " 2851,\n",
       " 2855,\n",
       " 2856,\n",
       " 2865,\n",
       " 2868,\n",
       " 2873,\n",
       " 2877,\n",
       " 2880,\n",
       " 2883,\n",
       " 2885,\n",
       " 2888,\n",
       " 2890,\n",
       " 2891,\n",
       " 2894,\n",
       " 2897,\n",
       " 2899,\n",
       " 2900,\n",
       " 2901,\n",
       " 2927,\n",
       " 2931,\n",
       " 2938,\n",
       " 2953,\n",
       " 3023,\n",
       " 3026,\n",
       " 3030,\n",
       " 3032,\n",
       " 3033,\n",
       " 3035,\n",
       " 3036,\n",
       " 3039,\n",
       " 3040,\n",
       " 3041,\n",
       " 3042,\n",
       " 3043,\n",
       " 3044,\n",
       " 3048,\n",
       " 3049,\n",
       " 3059,\n",
       " 3060,\n",
       " 3067,\n",
       " 3069,\n",
       " 3093,\n",
       " 3119,\n",
       " 3168,\n",
       " 3172,\n",
       " 3224,\n",
       " 3369,\n",
       " 3386,\n",
       " 3403,\n",
       " 3425,\n",
       " 3441,\n",
       " 3454,\n",
       " 3455,\n",
       " 3462,\n",
       " 3557,\n",
       " 3564,\n",
       " 3566,\n",
       " 3567,\n",
       " 3659,\n",
       " 3733,\n",
       " 3734,\n",
       " 3736,\n",
       " 3766,\n",
       " 3774,\n",
       " 3824,\n",
       " 3828,\n",
       " 3833,\n",
       " 3875,\n",
       " 3924,\n",
       " 3927,\n",
       " 3964,\n",
       " 4049,\n",
       " 4124,\n",
       " 4152,\n",
       " 4220,\n",
       " 4223,\n",
       " 4240,\n",
       " 4342,\n",
       " 4375,\n",
       " 4392,\n",
       " 4411,\n",
       " 4416,\n",
       " 4421,\n",
       " 4427,\n",
       " 4488,\n",
       " 4608,\n",
       " 4610,\n",
       " 4626,\n",
       " 4639,\n",
       " 4677,\n",
       " 4681,\n",
       " 4683,\n",
       " 4684,\n",
       " 4689,\n",
       " 4690,\n",
       " 4695,\n",
       " 4703,\n",
       " 4706,\n",
       " 4711,\n",
       " 4715,\n",
       " 4717,\n",
       " 4718,\n",
       " 4719,\n",
       " 4722,\n",
       " 4723,\n",
       " 4724,\n",
       " 4725,\n",
       " 4727,\n",
       " 4729,\n",
       " 4733,\n",
       " 4734]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query(queries, _and=False):\n",
    "    docs = []\n",
    "    for query in queries:\n",
    "        if \"*\" in query:\n",
    "            docs.append(query_permuterm_index(query, perm_index, rev_perm_index, inverted_list))\n",
    "            \n",
    "        else:\n",
    "            intermediate_docs = []\n",
    "            for id in inverted_list[query]:\n",
    "                intermediate_docs.append(id.data)\n",
    "            docs.append(intermediate_docs)\n",
    "    # return docs\n",
    "    if not _and:   \n",
    "        # return union of all sublists in docs\n",
    "        result = []\n",
    "        for l in docs:\n",
    "            for id in l:\n",
    "                if id not in result:\n",
    "                    result.append(id)\n",
    "        return sorted(result)\n",
    "    else:\n",
    "        result = set(docs[0])\n",
    "        for l in docs:\n",
    "            result = result.intersection(set(l))\n",
    "        return sorted(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = multi_query([\"g*e\", \"car\"], _and=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126,\n",
       " 128,\n",
       " 156,\n",
       " 159,\n",
       " 394,\n",
       " 724,\n",
       " 1908,\n",
       " 2531,\n",
       " 2839,\n",
       " 2850,\n",
       " 2938,\n",
       " 3042,\n",
       " 3067,\n",
       " 3224,\n",
       " 3736,\n",
       " 3824,\n",
       " 4223,\n",
       " 4427,\n",
       " 4681,\n",
       " 4690]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_step_one(queries):\n",
    "    # seperate queries into two lists, and and or lists. and words have double quotes around them\n",
    "    and_queries = []\n",
    "    or_queries = []\n",
    "    for query in queries:\n",
    "        if query[0] == '\"' and query[-1] == '\"':\n",
    "            and_queries.append(query[1:-1])\n",
    "        else:\n",
    "            or_queries.append(query)\n",
    "    if len(and_queries) == 0:\n",
    "        return multi_query(or_queries)\n",
    "    if len(or_queries) == 0:\n",
    "        return multi_query(and_queries, _and=True)\n",
    "    and_results = multi_query(and_queries, _and=True)\n",
    "    or_results = multi_query(or_queries)\n",
    "    return sorted(list(set(and_results) & set(or_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22,\n",
       " 25,\n",
       " 28,\n",
       " 37,\n",
       " 47,\n",
       " 54,\n",
       " 55,\n",
       " 57,\n",
       " 60,\n",
       " 80,\n",
       " 87,\n",
       " 88,\n",
       " 95,\n",
       " 102,\n",
       " 125,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 138,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 147,\n",
       " 148,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 177,\n",
       " 475,\n",
       " 478,\n",
       " 497,\n",
       " 522,\n",
       " 676,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 975,\n",
       " 1537,\n",
       " 1723,\n",
       " 1726,\n",
       " 2872,\n",
       " 2876,\n",
       " 2877,\n",
       " 2878,\n",
       " 3028,\n",
       " 3060,\n",
       " 3937,\n",
       " 4710,\n",
       " 4714,\n",
       " 4715]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_step_one([\"\\\"acci*t\\\"\", \"bodily\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USEFUL TELEPHONE NUMBERS \\nHow to make a claim \\nIf You need to make a legal expenses claim and this section is \\nshown as being operative on the Schedule, please refer to the \\nLegal Expenses Insurance Section of this Policy for details. For all \\nother claims please contact Us by calling the telephone number \\nprinted on Your Policy Schedule. \\nThe claims handler will take full details of the claim and guide You \\nthrough the next steps. Depending on the value and type of claim, \\nthe claims handler may seek help from a loss adjuster. Loss \\nadjusters are independent claims experts who will visit You or a \\nthird party claimant to assist with the assessment of the claim. \\nOnce We have been notified of a claim, We will tell Your broker. \\nThe notification letter gives Your broker the opportunity to become \\ninvolved in the claim if either You or they wish. Once the claim has \\nbeen settled, a letter is sent to Your broker confirming settlement \\nand the amounts paid. \\nDo \\n• Have details of Your policy number ready when notifying Us. \\nYou can find the policy number on the Schedule. \\n• Report any incidence of loss of Money, theft, attempted theft \\nor Damage by malicious persons to the police immediately. \\nYou should obtain a crime reference number (not an incident \\nreference number) from them if a crime has been committed. \\n• Carry out temporary repairs to the Property Insured to \\nprevent further loss. Please retain all invoices for work \\ncarried out. Remember, if You do not have Your own \\ncontractor, call the Business Emergency Assistance \\ntelephone no. on Your Schedule to arrange for an approved \\ncontractor to effect repairs, any time of the day or night. \\n• Notify Us of any claim or any incident which may lead to a \\nclaim as soon as possible. The sooner We are involved, the \\nmore opportunity We have to resolve the claim to Your \\nsatisfaction. You must notify Us within seven days if the \\nincident relates to Damage by riot, civil commotion, labour or \\npolitical disturbances, malicious persons, theft or attempted \\ntheft. \\n• Ensure that any letter or notice received is sent to Us \\nimmediately unanswered and unacknowledged. You must \\nalso send Us unanswered and unacknowledged any written \\nclaim, writ, summons or other document relating to a claim \\nand tell Us of any pending prosecution, coroner’s inquest or \\nfatal accident inquiry and give Us full details of any verbal \\nclaims made against You. \\n• Any Bodily Injury to an Employee should be reported to Us \\nregardless of whether a formal claim has been made against \\nYou. We can then decide whether We need to investigate \\nand provide advice to You. \\nDon’t \\n• Dispose of any evidence or damaged items - We may wish to \\nsee them. \\n• Wait for estimates to be obtained for work to be carried out \\nbefore notifying Us of a claim. \\n• Admit or deny responsibility for any incident involving Bodily \\nInjury to others or Damage to their property. '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.iloc[3060].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_name                                        7thEditionPolicy\n",
       "page_number                                                         0\n",
       "paragraph_number                                                    1\n",
       "text                Please read your policy.  Part of the policy i...\n",
       "tokenized           read policy policy page mark coverage selectio...\n",
       "posting_list        [agent, amount, approve, away, buy, check, com...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_word_index(df):\n",
    "    n_word_index = {}\n",
    "    for row in df.iterrows():\n",
    "        text = str(row[1][\"tokenized\"])\n",
    "        text = text.split()\n",
    "        for i in range(len(text) - 1):\n",
    "            n_word = text[i] + \" \" + text[i+1]\n",
    "            if n_word not in n_word_index:\n",
    "                n_word_index[n_word] = LinkedList()\n",
    "            n_word_index[n_word].append(row[0])\n",
    "    return n_word_index\n",
    "\n",
    "n_word_index = make_n_word_index(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in n_word_index:\n",
    "    n_word_index[key].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_n_word_index(query, n_word_index):\n",
    "    result = []\n",
    "    for id in n_word_index[query]:\n",
    "        result.append(id.data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_query(query, n_word_index):\n",
    "    words = query.split()\n",
    "    biwords = []\n",
    "    for i in range(len(words) - 1):\n",
    "        biwords.append(words[i] + \" \" + words[i+1])\n",
    "    result = []\n",
    "    for bw in biwords:\n",
    "        result.append(query_n_word_index(bw, n_word_index))\n",
    "    final = set(result[0])\n",
    "    for l in result:\n",
    "        final = final.intersection(set(l))\n",
    "    return sorted(list(final))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[127]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_query(\"liability policy sue\", n_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "658a82028ab00f880bc6bcdff014f37899cf9fd6fbfdda117e2e46094372bdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
